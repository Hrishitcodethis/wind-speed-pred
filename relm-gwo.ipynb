{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "406046bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b8e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/hrishityelchuri/Documents/windPred/raw/8.52 hrishit data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e6baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PeriodEnd'] = pd.to_datetime(df['PeriodEnd'])\n",
    "df['PeriodStart'] = pd.to_datetime(df['PeriodStart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03180fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('PeriodEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multivariate_lagged_dataset(df, target_col, feature_cols, lag=3):\n",
    "    \"\"\"\n",
    "    Create supervised learning data from multivariate time series.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing time series data for multiple variables\n",
    "    - target_col: string, name of the target variable column (e.g., 'WindSpeed10m')\n",
    "    - feature_cols: list of strings, names of feature columns to use (including target if desired)\n",
    "    - lag: number of past time steps to include as input features\n",
    "    \n",
    "    Returns:\n",
    "    - X: 2D NumPy array of shape (samples, features * lag)\n",
    "    - y: 1D NumPy array of target values (samples,)\n",
    "    \"\"\"\n",
    "    data = df[feature_cols].values\n",
    "    target_idx = feature_cols.index(target_col)\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(lag, len(df)):\n",
    "        # extract lagged observations for all features\n",
    "        X.append(data[i-lag:i].flatten())  # flatten to 1D array of length features*lag\n",
    "        y.append(data[i, target_idx])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd269fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RELM:\n",
    "    \"\"\"\n",
    "    Regularized Extreme Learning Machine (RELM) as per Huang et al.\n",
    "    Primal (N >= L):  beta = (I/C + H^T H)^(-1) H^T Y\n",
    "    Dual   (N <  L):  beta = H^T (I/C + H H^T)^(-1) Y\n",
    "\n",
    "    Supports activations: 'sigmoid' (stable), 'tanh', 'relu'\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=100, activation='tanh', C=1.0, random_state=None):\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.activation = activation\n",
    "        self.C = float(C)\n",
    "        self.random_state = random_state\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _init_weights(self, n_features):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        # Uniform draws as is common in ELM papers\n",
    "        self.W = rng.uniform(-1, 1, size=(self.n_hidden, n_features))\n",
    "        self.b = rng.uniform(-1, 1, size=(self.n_hidden,))\n",
    "\n",
    "    def _activation(self, X):\n",
    "        if self.activation == 'sigmoid':\n",
    "            # numerically stable sigmoid\n",
    "            X = np.clip(X, -500, 500)\n",
    "            return 1.0 / (1.0 + np.exp(-X))\n",
    "        if self.activation == 'tanh':\n",
    "            return np.tanh(X)\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0.0, X)\n",
    "        raise ValueError(f\"Unknown activation: {self.activation}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        N, d = X.shape\n",
    "        self._init_weights(d)\n",
    "        H = self._activation(X @ self.W.T + self.b)\n",
    "\n",
    "        if N >= self.n_hidden:\n",
    "            # Primal form\n",
    "            A = (np.eye(self.n_hidden) / self.C) + (H.T @ H)\n",
    "            B = H.T @ y\n",
    "            self.beta = np.linalg.solve(A, B)\n",
    "        else:\n",
    "            # Dual form\n",
    "            A = (np.eye(N) / self.C) + (H @ H.T)\n",
    "            B = y\n",
    "            self.beta = H.T @ np.linalg.solve(A, B)\n",
    "\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted.\")\n",
    "        X = np.asarray(X)\n",
    "        H = self._activation(X @ self.W.T + self.b)\n",
    "        Y = H @ self.beta\n",
    "        return Y.ravel() if Y.shape[1] == 1 else Y\n",
    "\n",
    "    def rmse(self, X, y):\n",
    "        yp = self.predict(X)\n",
    "        return float(np.sqrt(mean_squared_error(y, yp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec6ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multistep_targets(X, y, max_step=7):\n",
    "    \"\"\"\n",
    "    Build (X_step, y_step) for horizons 1..max_step without recursion.\n",
    "    For each step k, aligns X[:-k] with y[k:].\n",
    "    \"\"\"\n",
    "    targets = []\n",
    "    for step in range(1, max_step + 1):\n",
    "        target = y[step:]\n",
    "        X_valid = X[:-step]\n",
    "        targets.append((X_valid, target))\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d36823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mape(y_true, y_pred, min_denom=1.0):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = np.abs(y_true) >= min_denom\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0\n",
    "\n",
    "def sde(y_true, y_pred):\n",
    "    return float(np.std(np.array(y_true) - np.array(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01a69f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreyWolfOptimizer:\n",
    "    \"\"\"\n",
    "    Classic GWO (alpha, beta, delta) for continuous variables.\n",
    "    Allows integer rounding for selected dims (e.g., n_hidden).\n",
    "    \"\"\"\n",
    "    def __init__(self, obj_func, lb, ub, dim, num_wolves=20, max_iter=40,\n",
    "                 integer_index=None, seed=2025):\n",
    "        self.obj_func = obj_func\n",
    "        self.lb = np.array(lb, dtype=float)\n",
    "        self.ub = np.array(ub, dtype=float)\n",
    "        self.dim = dim\n",
    "        self.num_wolves = num_wolves\n",
    "        self.max_iter = max_iter\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.integer_index = set(integer_index or [])\n",
    "\n",
    "    def _clip(self, pos):\n",
    "        return np.minimum(np.maximum(pos, self.lb), self.ub)\n",
    "\n",
    "    def optimize(self):\n",
    "        # Initialize wolves within bounds\n",
    "        wolves = self.rng.uniform(self.lb, self.ub, (self.num_wolves, self.dim))\n",
    "\n",
    "        def eval_pack(W):\n",
    "            return np.array([self.obj_func(w) for w in W])\n",
    "\n",
    "        fitness = eval_pack(wolves)\n",
    "\n",
    "        # Sort and pick alpha, beta, delta\n",
    "        def sort_wolves(w, f):\n",
    "            idx = np.argsort(f)\n",
    "            return w[idx], f[idx]\n",
    "\n",
    "        wolves, fitness = sort_wolves(wolves, fitness)\n",
    "        alpha, beta, delta = wolves[0].copy(), wolves[1].copy(), wolves[2].copy()\n",
    "        alpha_score, beta_score, delta_score = float(fitness[0]), float(fitness[1]), float(fitness[2])\n",
    "\n",
    "        history = [(0, alpha_score)]\n",
    "\n",
    "        for t in range(1, self.max_iter + 1):\n",
    "            a = 2.0 - 2.0 * (t / self.max_iter)  # linearly decreases 2 -> 0\n",
    "\n",
    "            for i in range(self.num_wolves):\n",
    "                X = wolves[i]\n",
    "\n",
    "                def encircle(leader):\n",
    "                    r1 = self.rng.random(self.dim)\n",
    "                    r2 = self.rng.random(self.dim)\n",
    "                    A = 2 * a * r1 - a\n",
    "                    C = 2 * r2\n",
    "                    D = np.abs(C * leader - X)\n",
    "                    return leader - A * D\n",
    "\n",
    "                X1 = encircle(alpha)\n",
    "                X2 = encircle(beta)\n",
    "                X3 = encircle(delta)\n",
    "\n",
    "                newX = (X1 + X2 + X3) / 3.0\n",
    "                newX = self._clip(newX)\n",
    "\n",
    "                # enforce integer dims\n",
    "                for idx in self.integer_index:\n",
    "                    newX[idx] = np.round(newX[idx])\n",
    "\n",
    "                wolves[i] = newX\n",
    "\n",
    "            fitness = eval_pack(wolves)\n",
    "            wolves, fitness = sort_wolves(wolves, fitness)\n",
    "\n",
    "            if fitness[0] < alpha_score:\n",
    "                alpha, alpha_score = wolves[0].copy(), float(fitness[0])\n",
    "            beta, beta_score = wolves[1].copy(), float(fitness[1])\n",
    "            delta, delta_score = wolves[2].copy(), float(fitness[2])\n",
    "\n",
    "            history.append((t, alpha_score))\n",
    "\n",
    "        return alpha, alpha_score, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ddd1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['AirTemp','Azimuth','CloudOpacity','DewpointTemp','Dhi','Dni','Ebh',\n",
    "                   'WindDirection10m','Ghi','RelativeHumidity','SurfacePressure','WindSpeed10m']\n",
    "target_column = 'WindSpeed10m'\n",
    "lag_steps = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28efc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MULTISTEP_OBJECTIVE = False  # set True to optimize average RMSE over 1..H\n",
    "MAX_STEP_OBJECTIVE = 7\n",
    "RELM_ACTIVATION = 'tanh'\n",
    "LOG10C_BOUNDS = (-3.0, 3.0)\n",
    "N_HIDDEN_BOUNDS = (20, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91027ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WOLVES = 20\n",
    "MAX_ITERS = 60\n",
    "SEED = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9a93d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_multivariate_lagged_dataset(df, target_column, feature_columns, lag=lag_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16bfd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "train_end = int(0.7 * n_samples)\n",
    "val_end = int(0.85 * n_samples)\n",
    "\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test,  y_test  = X[val_end:], y[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "361488c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c0e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relm_val_rmse_one_step(params):\n",
    "    \"\"\"\n",
    "    Objective: one-step-ahead validation RMSE.\n",
    "    params: [log10(C), n_hidden]\n",
    "    \"\"\"\n",
    "    logC, n_hidden = float(params[0]), int(np.round(params[1]))\n",
    "    C = 10.0 ** logC\n",
    "    n_hidden = max(1, n_hidden)\n",
    "\n",
    "    model = RELM(n_hidden=n_hidden, activation=RELM_ACTIVATION, C=C, random_state=42)\n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        rmse = model.rmse(X_val_scaled, y_val)\n",
    "    except Exception:\n",
    "        rmse = 1e9  # penalize numerical failures\n",
    "    return rmse\n",
    "\n",
    "def relm_val_rmse_multistep(params, max_step=7):\n",
    "    \"\"\"\n",
    "    Objective: average RMSE over validation horizons 1..max_step (non-recursive).\n",
    "    \"\"\"\n",
    "    logC, n_hidden = float(params[0]), int(np.round(params[1]))\n",
    "    C = 10.0 ** logC\n",
    "    n_hidden = max(1, n_hidden)\n",
    "\n",
    "    model = RELM(n_hidden=n_hidden, activation=RELM_ACTIVATION, C=C, random_state=42)\n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Build multistep targets **on the validation split**\n",
    "        ms_val = create_multistep_targets(X_val_scaled, y_val, max_step=max_step)\n",
    "        rmses = []\n",
    "        for _, (Xv_step, yv_step) in enumerate(ms_val, 1):\n",
    "            y_pred = model.predict(Xv_step)\n",
    "            rmses.append(np.sqrt(mean_squared_error(yv_step, y_pred)))\n",
    "        rmse = float(np.mean(rmses))\n",
    "    except Exception:\n",
    "        rmse = 1e9\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "506087ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MULTISTEP_OBJECTIVE:\n",
    "    obj_func = lambda p: relm_val_rmse_multistep(p, max_step=MAX_STEP_OBJECTIVE)\n",
    "else:\n",
    "    obj_func = relm_val_rmse_one_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b4ea21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [LOG10C_BOUNDS[0], N_HIDDEN_BOUNDS[0]]\n",
    "ub = [LOG10C_BOUNDS[1], N_HIDDEN_BOUNDS[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4171eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwo = GreyWolfOptimizer(\n",
    "    obj_func=obj_func,\n",
    "    lb=lb, ub=ub, dim=2,\n",
    "    num_wolves=N_WOLVES, max_iter=MAX_ITERS,\n",
    "    integer_index=[1],  # n_hidden is integer\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af2a1353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GWO] Best validation score (RMSE): 1.032335\n",
      "[GWO] Best hyperparameters: C = 0.00140916, n_hidden = 581, activation = tanh\n"
     ]
    }
   ],
   "source": [
    "best_params, best_val_score, history = gwo.optimize()\n",
    "best_logC, best_hidden = float(best_params[0]), int(np.round(best_params[1]))\n",
    "best_C = 10.0 ** best_logC\n",
    "\n",
    "print(f\"[GWO] Best validation score (RMSE): {best_val_score:.6f}\")\n",
    "print(f\"[GWO] Best hyperparameters: C = {best_C:.6g}, n_hidden = {best_hidden}, activation = {RELM_ACTIVATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85c3a161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RELM at 0x1075928d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval_scaled = np.vstack([X_train_scaled, X_val_scaled])\n",
    "y_trainval = np.concatenate([y_train, y_val])\n",
    "\n",
    "final_model = RELM(n_hidden=best_hidden, activation=RELM_ACTIVATION, C=best_C, random_state=42)\n",
    "final_model.fit(X_trainval_scaled, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a214371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = final_model.rmse(X_test_scaled, y_test)\n",
    "test_mae = mean_absolute_error(y_test, final_model.predict(X_test_scaled))\n",
    "test_mape = safe_mape(y_test, final_model.predict(X_test_scaled))\n",
    "test_sde  = sde(y_test, final_model.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2448fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-step Test Metrics ===\n",
      "MAE  : 0.785056\n",
      "RMSE : 0.998352\n",
      "MAPE : 30.234%\n",
      "SDE  : 0.955556\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== One-step Test Metrics ===\")\n",
    "print(f\"MAE  : {test_mae:.6f}\")\n",
    "print(f\"RMSE : {test_rmse:.6f}\")\n",
    "print(f\"MAPE : {test_mape:.3f}%\")\n",
    "print(f\"SDE  : {test_sde:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0a79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEP_EVAL = 7\n",
    "multistep_data_test = create_multistep_targets(X_test_scaled, y_test, max_step=MAX_STEP_EVAL)\n",
    "\n",
    "rows = []\n",
    "for step, (step_X, step_y) in enumerate(multistep_data_test, 1):\n",
    "    y_pred_step = final_model.predict(step_X)\n",
    "    mae = mean_absolute_error(step_y, y_pred_step)\n",
    "    rmse = np.sqrt(mean_squared_error(step_y, y_pred_step))\n",
    "    mape_val = safe_mape(step_y, y_pred_step)\n",
    "    sde_val = sde(step_y, y_pred_step)\n",
    "    rows.append({\"Step\": step, \"MAE\": mae, \"RMSE\": rmse, \"MAPE (%)\": mape_val, \"SDE\": sde_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "982706d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-step Test Metrics (non-recursive, 1..7) ===\n",
      " Step      MAE     RMSE  MAPE (%)      SDE\n",
      "    1 0.852299 1.080472 32.731733 1.041054\n",
      "    2 0.937051 1.190286 35.350458 1.154622\n",
      "    3 1.021617 1.301549 38.182487 1.269037\n",
      "    4 1.101322 1.401289 40.719982 1.371169\n",
      "    5 1.169479 1.481541 43.041351 1.453110\n",
      "    6 1.225065 1.540986 45.021263 1.513702\n",
      "    7 1.268643 1.583406 46.783640 1.556896\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(rows, columns=[\"Step\", \"MAE\", \"RMSE\", \"MAPE (%)\", \"SDE\"])\n",
    "print(\"\\n=== Multi-step Test Metrics (non-recursive, 1..7) ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c617c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
