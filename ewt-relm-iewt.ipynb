{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eb5f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba962d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/hrishityelchuri/Documents/windPred/raw/8.52 hrishit data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2255411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PeriodEnd'] = pd.to_datetime(df['PeriodEnd'])\n",
    "df['PeriodStart'] = pd.to_datetime(df['PeriodStart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "269c73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('PeriodEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f364189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multivariate_lagged_dataset(df, target_col, feature_cols, lag=3):\n",
    "    data = df[feature_cols].values\n",
    "    target_idx = feature_cols.index(target_col)\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(lag, len(df)):\n",
    "        # extract lagged observations for all features\n",
    "        X.append(data[i-lag:i].flatten())  # flatten to 1D array of length features*lag\n",
    "        y.append(data[i, target_idx])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "367ac846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mape(y_true, y_pred, min_denom=1.0):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = np.abs(y_true) >= min_denom\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def sde(y_true, y_pred):\n",
    "    return float(np.std(np.array(y_true) - np.array(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbccda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewt_boundaries_equal_energy(spectrum, N):\n",
    "    \"\"\"Fallback: Equal-energy segmentation.\"\"\"\n",
    "    energy = np.cumsum(spectrum) / np.sum(spectrum)\n",
    "    boundaries = []\n",
    "    for k in range(1, N):\n",
    "        idx = np.argmin(np.abs(energy - k / N))\n",
    "        boundaries.append(idx / len(spectrum) * np.pi)\n",
    "    return boundaries\n",
    "\n",
    "def ewt_boundaries(spectrum, N, smooth_sigma=2):\n",
    "    \"\"\"\n",
    "    Spectrum-peak-based boundary detection from EWT paper.\n",
    "    If not enough peaks found, falls back to equal-energy method.\n",
    "    \"\"\"\n",
    "    # Smooth spectrum\n",
    "    spectrum_smooth = gaussian_filter1d(spectrum, sigma=smooth_sigma)\n",
    "\n",
    "    # Find peaks\n",
    "    peaks, _ = find_peaks(spectrum_smooth)\n",
    "\n",
    "    if len(peaks) < N - 1:\n",
    "        print(\"[EWT] Warning: Not enough peaks found, falling back to equal-energy boundaries.\")\n",
    "        return ewt_boundaries_equal_energy(spectrum, N)\n",
    "\n",
    "    # Sort peaks by amplitude\n",
    "    prominences = spectrum_smooth[peaks]\n",
    "    sorted_peaks = [p for _, p in sorted(zip(prominences, peaks), reverse=True)]\n",
    "    \n",
    "    # Take N-1 most prominent\n",
    "    sorted_peaks = sorted(sorted_peaks[:N-1])\n",
    "\n",
    "    # Convert to radian boundaries\n",
    "    boundaries = [p / len(spectrum) * np.pi for p in sorted_peaks]\n",
    "    return boundaries\n",
    "\n",
    "def make_filter_bank(boundaries, L):\n",
    "    freqs = np.linspace(0, np.pi, L//2+1)\n",
    "    mfb = []\n",
    "\n",
    "    # Scaling (low-pass)\n",
    "    phi = np.zeros_like(freqs)\n",
    "    phi[freqs <= boundaries[0]] = 1\n",
    "    mfb.append(phi)\n",
    "\n",
    "    # Wavelets\n",
    "    for i in range(len(boundaries)):\n",
    "        psi = np.zeros_like(freqs)\n",
    "        if i == len(boundaries) - 1:\n",
    "            mask = (freqs > boundaries[i])\n",
    "        else:\n",
    "            mask = (freqs > boundaries[i]) & (freqs <= boundaries[i+1])\n",
    "        psi[mask] = 1\n",
    "        mfb.append(psi)\n",
    "    return mfb\n",
    "\n",
    "def EWT1D(signal, N=3, smooth_sigma=2):\n",
    "    \"\"\"EWT using spectrum-peak-based boundaries.\"\"\"\n",
    "    L = len(signal)\n",
    "    spectrum = np.abs(fft(signal))[:L//2+1]\n",
    "    boundaries = ewt_boundaries(spectrum, N, smooth_sigma=smooth_sigma)\n",
    "    mfb = make_filter_bank(boundaries, L)\n",
    "\n",
    "    modes = []\n",
    "    spectrum_full = fft(signal)\n",
    "    for filt in mfb:\n",
    "        filt_full = np.concatenate([filt, filt[-2:0:-1]])\n",
    "        mode_freq = spectrum_full * filt_full\n",
    "        mode_time = np.real(ifft(mode_freq))\n",
    "        modes.append(mode_time)\n",
    "    return np.array(modes), mfb, boundaries\n",
    "\n",
    "def iEWT1D(modes, mfb):\n",
    "    \"\"\"Inverse EWT.\"\"\"\n",
    "    return np.sum(modes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b76cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RELM:\n",
    "    def __init__(self, n_hidden=100, activation='tanh', C=1.0, random_state=None):\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.activation = activation\n",
    "        self.C = float(C)\n",
    "        self.random_state = random_state\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _init_weights(self, n_features):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.W = rng.uniform(-1, 1, size=(self.n_hidden, n_features))\n",
    "        self.b = rng.uniform(-1, 1, size=(self.n_hidden,))\n",
    "\n",
    "    def _activation(self, X):\n",
    "        if self.activation == 'sigmoid':\n",
    "            X = np.clip(X, -500, 500)\n",
    "            return 1.0 / (1.0 + np.exp(-X))\n",
    "        if self.activation == 'tanh':\n",
    "            return np.tanh(X)\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0.0, X)\n",
    "        raise ValueError(f\"Unknown activation: {self.activation}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        N, d = X.shape\n",
    "        self._init_weights(d)\n",
    "        H = self._activation(X @ self.W.T + self.b)\n",
    "\n",
    "        if N >= self.n_hidden:\n",
    "            A = (np.eye(self.n_hidden) / self.C) + (H.T @ H)\n",
    "            B = H.T @ y\n",
    "            self.beta = np.linalg.solve(A, B)\n",
    "        else:\n",
    "            A = (np.eye(N) / self.C) + (H @ H.T)\n",
    "            B = y\n",
    "            self.beta = H.T @ np.linalg.solve(A, B)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted.\")\n",
    "        H = self._activation(np.asarray(X) @ self.W.T + self.b)\n",
    "        Y = H @ self.beta\n",
    "        return Y.ravel() if Y.shape[1] == 1 else Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9ef3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewt_relm_iewt_pipeline(df, target_column, feature_columns, lag_steps=12, n_modes=4,\n",
    "                           n_hidden=100, C=1.0, activation='tanh', max_step_eval=7):\n",
    "\n",
    "    # Step 1: EWT decomposition of target\n",
    "    signal = df[target_column].values\n",
    "    ewt_modes, mfb, boundaries = EWT1D(signal, N=n_modes)\n",
    "\n",
    "    # Split indexes after lag\n",
    "    n_samples = len(signal) - lag_steps\n",
    "    train_end = int(0.7 * n_samples)\n",
    "    val_end = int(0.85 * n_samples)\n",
    "\n",
    "    # Step 2: Train RELM for each mode\n",
    "    mode_preds_test = []\n",
    "    for mode_idx in range(n_modes):\n",
    "        mode_series = ewt_modes[mode_idx, :]\n",
    "        df_mode = df.copy()\n",
    "        df_mode[target_column] = mode_series\n",
    "\n",
    "        X_mode, y_mode = create_multivariate_lagged_dataset(df_mode, target_column, feature_columns, lag=lag_steps)\n",
    "        X_train, y_train = X_mode[:train_end], y_mode[:train_end]\n",
    "        X_test = X_mode[val_end:]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred_test_mode = model.predict(X_test_scaled)\n",
    "        mode_preds_test.append(y_pred_test_mode)\n",
    "\n",
    "    # Step 3: IEWT reconstruction\n",
    "    mode_preds_test = np.array(mode_preds_test)\n",
    "    y_pred_final = iEWT1D(mode_preds_test, mfb)\n",
    "\n",
    "    # Step 4: Metrics (one-step)\n",
    "    y_true_test = df[target_column].values[lag_steps+val_end:]\n",
    "    mae = mean_absolute_error(y_true_test, y_pred_final)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_true_test, y_pred_final))\n",
    "    mape_val = safe_mape(y_true_test, y_pred_final)\n",
    "    sde_val = sde(y_true_test, y_pred_final)\n",
    "\n",
    "    print(\"\\n=== One-step Test Metrics ===\")\n",
    "    print(f\"MAE  : {mae:.6f}\")\n",
    "    print(f\"RMSE : {rmse_val:.6f}\")\n",
    "    print(f\"MAPE : {mape_val:.3f}%\")\n",
    "    print(f\"SDE  : {sde_val:.6f}\")\n",
    "\n",
    "    # Step 5: Multi-step metrics\n",
    "    multistep_rows = []\n",
    "    for step in range(1, max_step_eval + 1):\n",
    "        mode_preds_step = []\n",
    "        for mode_idx in range(n_modes):\n",
    "            mode_series = ewt_modes[mode_idx, :]\n",
    "            df_mode = df.copy()\n",
    "            df_mode[target_column] = mode_series\n",
    "\n",
    "            X_mode, y_mode = create_multivariate_lagged_dataset(df_mode, target_column, feature_columns, lag=lag_steps)\n",
    "            X_train, y_train = X_mode[:train_end], y_mode[:train_end]\n",
    "            X_test_step = X_mode[val_end:-step]\n",
    "            y_test_step = y_mode[val_end+step:]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test_step)\n",
    "\n",
    "            model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=42)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            mode_preds_step.append(model.predict(X_test_scaled))\n",
    "\n",
    "        mode_preds_step = np.array(mode_preds_step)\n",
    "        y_pred_step_final = iEWT1D(mode_preds_step, mfb)\n",
    "        y_true_step = df[target_column].values[lag_steps+val_end+step:]\n",
    "\n",
    "        multistep_rows.append({\n",
    "            \"Step\": step,\n",
    "            \"MAE\": mean_absolute_error(y_true_step, y_pred_step_final),\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_true_step, y_pred_step_final)),\n",
    "            \"MAPE (%)\": safe_mape(y_true_step, y_pred_step_final),\n",
    "            \"SDE\": sde(y_true_step, y_pred_step_final)\n",
    "        })\n",
    "\n",
    "    multistep_df = pd.DataFrame(multistep_rows)\n",
    "    print(\"\\n=== Multi-step Test Metrics ===\")\n",
    "    print(multistep_df.to_string(index=False))\n",
    "\n",
    "    return mae, rmse_val, mape_val, sde_val, multistep_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44525d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['AirTemp','Azimuth','CloudOpacity','DewpointTemp','Dhi','Dni','Ebh',\n",
    "                    'WindDirection10m','Ghi','RelativeHumidity','SurfacePressure','WindSpeed10m']\n",
    "target_column = 'WindSpeed10m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd4009f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-step Test Metrics ===\n",
      "MAE  : 2.889451\n",
      "RMSE : 3.419612\n",
      "MAPE : 110.405%\n",
      "SDE  : 2.094025\n",
      "\n",
      "=== Multi-step Test Metrics ===\n",
      " Step      MAE     RMSE   MAPE (%)      SDE\n",
      "    1 2.907520 3.463841 110.307476 2.165256\n",
      "    2 2.927575 3.506699 110.465468 2.233091\n",
      "    3 2.946537 3.541221 110.364851 2.286986\n",
      "    4 2.963732 3.567115 110.629683 2.326834\n",
      "    5 2.976152 3.584364 110.904148 2.353136\n",
      "    6 2.980362 3.589067 110.728046 2.360247\n",
      "    7 2.973807 3.577168 110.326572 2.342320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.8894509619518502,\n",
       " np.float64(3.4196123441891224),\n",
       " np.float64(110.40465491962148),\n",
       " 2.0940245052461046,\n",
       "    Step       MAE      RMSE    MAPE (%)       SDE\n",
       " 0     1  2.907520  3.463841  110.307476  2.165256\n",
       " 1     2  2.927575  3.506699  110.465468  2.233091\n",
       " 2     3  2.946537  3.541221  110.364851  2.286986\n",
       " 3     4  2.963732  3.567115  110.629683  2.326834\n",
       " 4     5  2.976152  3.584364  110.904148  2.353136\n",
       " 5     6  2.980362  3.589067  110.728046  2.360247\n",
       " 6     7  2.973807  3.577168  110.326572  2.342320)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewt_relm_iewt_pipeline(df, target_column, feature_columns,\n",
    "                       lag_steps=12, n_modes=4,\n",
    "                       n_hidden=100, C=1.0, activation='tanh',\n",
    "                       max_step_eval=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9291d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
