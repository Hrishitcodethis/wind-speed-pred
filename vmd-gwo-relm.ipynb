{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804498bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft, ifft, fftshift, ifftshift\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d7f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VMD(signal, alpha=2000., tau=0., K=3, DC=0, init=1, tol=1e-7, N_iter=500):\n",
    "    \"\"\"\n",
    "    Variational Mode Decomposition (VMD).\n",
    "    signal: 1D array (real)\n",
    "    alpha: balancing parameter of data-fidelity\n",
    "    tau: time-step of the dual ascent (0 for noise-slack)\n",
    "    K: number of modes\n",
    "    DC: 0 -> no DC part, 1 -> allow a DC part\n",
    "    init: 0 = all omegas = 0, 1 = uniformly spaced, 2 = random\n",
    "    tol: convergence tolerance\n",
    "    N_iter: maximum iterations\n",
    "    Returns: modes (K, len(signal)), center freqs (K)\n",
    "    \"\"\"\n",
    "    f = np.copy(signal).astype(float)\n",
    "    N = len(f)\n",
    "    # Mirror signal to reduce boundary effects (as in original code)\n",
    "    T = N\n",
    "    # time domain discrete samples\n",
    "    t = np.arange(0, T) / T\n",
    "\n",
    "    # Fourier domain discretization\n",
    "    freqs = np.arange(0, T) / T\n",
    "    # Fourier transform of signal\n",
    "    f_hat = fft(f)\n",
    "    f_hat = np.concatenate((f_hat[T//2:], f_hat[:T//2]))  # fftshift-like (centered)\n",
    "    # initialize u_hat, omega\n",
    "    u_hat = np.zeros((K, T), dtype=complex)\n",
    "    omega = np.zeros(K)\n",
    "\n",
    "    # initialize omegas\n",
    "    if init == 1:\n",
    "        omega = 0.5 * (np.arange(K) / K)  # uniformly spaced positive freqs\n",
    "    elif init == 2:\n",
    "        rng = np.random.default_rng(0)\n",
    "        omega = rng.random(K)\n",
    "    else:\n",
    "        omega[:] = 0.0\n",
    "\n",
    "    # if DC mode requested force first omega = 0\n",
    "    if DC:\n",
    "        omega[0] = 0.0\n",
    "\n",
    "    # Lagrangian multipliers\n",
    "    lambda_hat = np.zeros(T, dtype=complex)\n",
    "\n",
    "    # main loop\n",
    "    uDiff = tol + 1.0\n",
    "    n = 0\n",
    "    # Precompute frequency array (positive)\n",
    "    k = np.concatenate((np.arange(0, T//2), np.arange(-T//2, 0)))\n",
    "    freqs_full = k / T  # range -0.5 .. 0.5\n",
    "\n",
    "    while (uDiff > tol) and (n < N_iter):\n",
    "        u_hat_prev = u_hat.copy()\n",
    "        # update each mode in frequency domain\n",
    "        for i in range(K):\n",
    "            # calculate residual excluding current mode\n",
    "            sum_others = np.sum(u_hat, axis=0) - u_hat[i]\n",
    "            # residual = f_hat - sum_others - lambda/2\n",
    "            residual = f_hat - sum_others - lambda_hat / 2.0\n",
    "            # update u_hat_i (equation for quadratic problem)\n",
    "            denom = 1.0 + alpha * (freqs_full - omega[i])**2\n",
    "            u_hat[i] = residual / denom\n",
    "\n",
    "            # enforce DC condition\n",
    "            if DC and i == 0:\n",
    "                u_hat[i][freqs_full != 0] = 0.0\n",
    "\n",
    "        # update omega (center frequencies)\n",
    "        for i in range(K):\n",
    "            # avoid division by zero: use real parts for numerator/denominator\n",
    "            ui = u_hat[i]\n",
    "            # numerator: sum(freq * |u_hat|^2)\n",
    "            num = np.sum(freqs_full * (np.abs(ui)**2))\n",
    "            den = np.sum(np.abs(ui)**2) + 1e-16\n",
    "            omega[i] = num / den\n",
    "\n",
    "        # dual ascent (update lambda)\n",
    "        sum_u = np.sum(u_hat, axis=0)\n",
    "        lambda_hat = lambda_hat + tau * (sum_u - f_hat)\n",
    "\n",
    "        # compute convergence\n",
    "        uDiff = np.sum([np.linalg.norm(u_hat[i] - u_hat_prev[i])**2 for i in range(K)])\n",
    "        n += 1\n",
    "\n",
    "    # reconstruct time-domain modes (unshifted)\n",
    "    # inverse shift of u_hat to match ifft ordering\n",
    "    # undo earlier fftshift-like concatenation:\n",
    "    u_hat_unshift = np.concatenate((u_hat[:, T//2:], u_hat[:, :T//2]), axis=1)\n",
    "    modes = np.real(ifft(u_hat_unshift, axis=1))\n",
    "    return modes, omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7472efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RELM:\n",
    "    def __init__(self, n_hidden=100, activation='tanh', C=1.0, random_state=None):\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.activation = activation\n",
    "        self.C = float(C)\n",
    "        self.random_state = random_state\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _init_weights(self, n_features):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.W = rng.uniform(-1, 1, size=(self.n_hidden, n_features))\n",
    "        self.b = rng.uniform(-1, 1, size=(self.n_hidden,))\n",
    "\n",
    "    def _activation(self, X):\n",
    "        if self.activation == 'sigmoid':\n",
    "            X = np.clip(X, -500, 500)\n",
    "            return 1.0 / (1.0 + np.exp(-X))\n",
    "        if self.activation == 'tanh':\n",
    "            return np.tanh(X)\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0.0, X)\n",
    "        raise ValueError(\"Unknown activation\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X); y = np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1,1)\n",
    "        N, d = X.shape\n",
    "        self._init_weights(d)\n",
    "        H = self._activation(X @ self.W.T + self.b)\n",
    "        if N >= self.n_hidden:\n",
    "            A = (np.eye(self.n_hidden) / self.C) + (H.T @ H)\n",
    "            B = H.T @ y\n",
    "            self.beta = np.linalg.solve(A, B)\n",
    "        else:\n",
    "            A = (np.eye(N) / self.C) + (H @ H.T)\n",
    "            B = y\n",
    "            self.beta = H.T @ np.linalg.solve(A, B)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model not fitted.\")\n",
    "        H = self._activation(np.asarray(X) @ self.W.T + self.b)\n",
    "        Y = H @ self.beta\n",
    "        return Y.ravel() if Y.shape[1] == 1 else Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c7ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWO:\n",
    "    def __init__(self, obj_func, lb, ub, dim, n_agents=12, n_iter=25, seed=42):\n",
    "        self.obj = obj_func\n",
    "        self.lb = np.array(lb, dtype=float)\n",
    "        self.ub = np.array(ub, dtype=float)\n",
    "        self.dim = dim\n",
    "        self.n_agents = n_agents\n",
    "        self.n_iter = n_iter\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def optimize(self):\n",
    "        wolves = self.rng.uniform(self.lb, self.ub, size=(self.n_agents, self.dim))\n",
    "        fitness = np.array([self.obj(w) for w in wolves])\n",
    "        idx = np.argsort(fitness)\n",
    "        alpha, beta, delta = wolves[idx[0]].copy(), wolves[idx[1]].copy(), wolves[idx[2]].copy()\n",
    "        f_alpha, f_beta, f_delta = float(fitness[idx[0]]), float(fitness[idx[1]]), float(fitness[idx[2]])\n",
    "        for t in range(self.n_iter):\n",
    "            a = 2 - 2 * (t / (self.n_iter - 1 + 1e-9))\n",
    "            for i in range(self.n_agents):\n",
    "                X = wolves[i].copy()\n",
    "                for j in range(self.dim):\n",
    "                    r1, r2 = self.rng.random(), self.rng.random()\n",
    "                    A1 = 2 * a * r1 - a; C1 = 2 * r2\n",
    "                    D_alpha = abs(C1 * alpha[j] - X[j]); X1 = alpha[j] - A1 * D_alpha\n",
    "\n",
    "                    r1, r2 = self.rng.random(), self.rng.random()\n",
    "                    A2 = 2 * a * r1 - a; C2 = 2 * r2\n",
    "                    D_beta = abs(C2 * beta[j] - X[j]); X2 = beta[j] - A2 * D_beta\n",
    "\n",
    "                    r1, r2 = self.rng.random(), self.rng.random()\n",
    "                    A3 = 2 * a * r1 - a; C3 = 2 * r2\n",
    "                    D_delta = abs(C3 * delta[j] - X[j]); X3 = delta[j] - A3 * D_delta\n",
    "\n",
    "                    X[j] = (X1 + X2 + X3) / 3.0\n",
    "                wolves[i] = np.clip(X, self.lb, self.ub)\n",
    "            fitness = np.array([self.obj(w) for w in wolves])\n",
    "            idx = np.argsort(fitness)\n",
    "            if fitness[idx[0]] < f_alpha:\n",
    "                alpha, f_alpha = wolves[idx[0]].copy(), float(fitness[idx[0]])\n",
    "            if fitness[idx[1]] < f_beta:\n",
    "                beta, f_beta = wolves[idx[1]].copy(), float(fitness[idx[1]])\n",
    "            if fitness[idx[2]] < f_delta:\n",
    "                delta, f_delta = wolves[idx[2]].copy(), float(fitness[idx[2]])\n",
    "        return alpha, f_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb0a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multivariate_lagged_dataset(df, target_col, feature_cols, lag=3):\n",
    "    data = df[feature_cols].values\n",
    "    target_idx = feature_cols.index(target_col)\n",
    "    X, y = [], []\n",
    "    for i in range(lag, len(df)):\n",
    "        X.append(data[i-lag:i].flatten())\n",
    "        y.append(data[i, target_idx])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def safe_mape(y_true, y_pred, min_denom=1.0):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    mask = np.abs(y_true) >= min_denom\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100)\n",
    "\n",
    "def sde(y_true, y_pred):\n",
    "    return float(np.std(np.asarray(y_true) - np.asarray(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8dab2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_relm_params(position, Hmin=20, Hmax=500, Cmin_log=-4, Cmax_log=4):\n",
    "    h_raw, logC, act_raw = position\n",
    "    n_hidden = int(np.round(Hmin + np.clip(h_raw, 0, 1) * (Hmax - Hmin)))\n",
    "    n_hidden = int(np.clip(n_hidden, Hmin, Hmax))\n",
    "    C = 10.0 ** float(np.clip(logC, Cmin_log, Cmax_log))\n",
    "    act_idx = int(np.round(np.clip(act_raw, 0, 2)))\n",
    "    activation = ['tanh', 'sigmoid', 'relu'][act_idx]\n",
    "    return n_hidden, C, activation\n",
    "\n",
    "def make_relm_objective(X_train, y_train, X_val, y_val, random_state=42,\n",
    "                        Hmin=20, Hmax=500, Cmin_log=-4, Cmax_log=4):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_val_s = scaler.transform(X_val)\n",
    "    def objective(position):\n",
    "        n_hidden, C, activation = decode_relm_params(position, Hmin=Hmin, Hmax=Hmax, Cmin_log=Cmin_log, Cmax_log=Cmax_log)\n",
    "        try:\n",
    "            model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "            model.fit(X_train_s, y_train)\n",
    "            y_pred = model.predict(X_val_s)\n",
    "            return float(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        except Exception:\n",
    "            return 1e6\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e1b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmd_gwo_relm_pipeline(\n",
    "    df,\n",
    "    target_column,\n",
    "    feature_columns,\n",
    "    lag_steps=12,\n",
    "    K_modes=4,\n",
    "    vmd_alpha=2000.,\n",
    "    vmd_tau=0.,\n",
    "    vmd_init=1,\n",
    "    vmd_DC=0,\n",
    "    vmd_tol=1e-7,\n",
    "    vmd_Niter=500,\n",
    "    gwo_agents=12,\n",
    "    gwo_iters=25,\n",
    "    random_state=42,\n",
    "    Hmin=20, Hmax=500,\n",
    "    Cmin_log=-4, Cmax_log=4,\n",
    "    max_step_eval=7\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns dict with:\n",
    "      - per_mode_info (list of best params)\n",
    "      - one_step_metrics (on reconstructed forecast)\n",
    "      - multistep_df (direct multi-step reconstructed metrics)\n",
    "      - modes (array K x L), reconstructed prediction array, and true test array\n",
    "    \"\"\"\n",
    "    # 1) VMD decompose target\n",
    "    signal = df[target_column].values.astype(float)\n",
    "    modes, omegas = VMD(signal, alpha=vmd_alpha, tau=vmd_tau, K=K_modes, DC=vmd_DC, init=vmd_init, tol=vmd_tol, N_iter=vmd_Niter)\n",
    "    # modes shape (K, L)\n",
    "\n",
    "    L = modes.shape[1]\n",
    "    # Build identical lagging scheme as earlier: lag removes first `lag_steps` samples\n",
    "    n_samples = L - lag_steps\n",
    "    if n_samples <= 0:\n",
    "        raise ValueError(\"lag_steps too large for series length after VMD.\")\n",
    "    train_end = int(0.7 * n_samples)\n",
    "    val_end = int(0.85 * n_samples)\n",
    "\n",
    "    per_mode_info = []\n",
    "    test_mode_preds = []\n",
    "    test_mode_lengths = []\n",
    "\n",
    "    for m in range(K_modes):\n",
    "        mode_series = modes[m, :]\n",
    "        df_mode = df.copy()\n",
    "        df_mode[target_column] = mode_series\n",
    "\n",
    "        X_mode, y_mode = create_multivariate_lagged_dataset(df_mode, target_column, feature_columns, lag=lag_steps)\n",
    "        X_train, y_train = X_mode[:train_end], y_mode[:train_end]\n",
    "        X_val, y_val     = X_mode[train_end:val_end], y_mode[train_end:val_end]\n",
    "        X_test, y_test   = X_mode[val_end:], y_mode[val_end:]\n",
    "\n",
    "        if len(X_train) < 5 or len(X_val) < 1 or len(X_test) < 1:\n",
    "            print(f\"[Mode {m+1}] insufficient data for train/val/test splits; skipping.\")\n",
    "            per_mode_info.append({\"mode\": m+1, \"skipped\": True})\n",
    "            test_mode_preds.append(np.zeros_like(X_test[:,0]) if X_test.size else np.array([]))\n",
    "            test_mode_lengths.append(len(X_test))\n",
    "            continue\n",
    "\n",
    "        # objective and GWO\n",
    "        obj = make_relm_objective(X_train, y_train, X_val, y_val, random_state=random_state,\n",
    "                                  Hmin=Hmin, Hmax=Hmax, Cmin_log=Cmin_log, Cmax_log=Cmax_log)\n",
    "\n",
    "        lb = np.array([0.0, Cmin_log, 0.0], dtype=float)   # [h_raw, logC, act_raw]\n",
    "        ub = np.array([1.0, Cmax_log, 2.0], dtype=float)\n",
    "\n",
    "        gwo = GWO(obj, lb, ub, dim=3, n_agents=gwo_agents, n_iter=gwo_iters, seed=random_state + m)\n",
    "        best_pos, best_fit = gwo.optimize()\n",
    "        n_hidden, C, activation = decode_relm_params(best_pos, Hmin=Hmin, Hmax=Hmax, Cmin_log=Cmin_log, Cmax_log=Cmax_log)\n",
    "\n",
    "        # train final on train+val and predict test\n",
    "        scaler = StandardScaler()\n",
    "        X_trval = np.vstack([X_train, X_val])\n",
    "        y_trval = np.concatenate([y_train, y_val])\n",
    "        X_trval_s = scaler.fit_transform(X_trval)\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "\n",
    "        model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "        model.fit(X_trval_s, y_trval)\n",
    "        y_pred_test_mode = model.predict(X_test_s)\n",
    "\n",
    "        per_mode_info.append({\n",
    "            \"mode\": m+1,\n",
    "            \"best_val_rmse\": float(best_fit),\n",
    "            \"n_hidden\": int(n_hidden),\n",
    "            \"C\": float(C),\n",
    "            \"activation\": activation,\n",
    "            \"test_len\": int(len(y_test))\n",
    "        })\n",
    "\n",
    "        test_mode_preds.append(y_pred_test_mode)\n",
    "        test_mode_lengths.append(len(y_test))\n",
    "\n",
    "    # Align test predictions and reconstruct by summation\n",
    "    n_test = None\n",
    "    for ln in test_mode_lengths:\n",
    "        if ln:\n",
    "            n_test = ln\n",
    "            break\n",
    "    if n_test is None:\n",
    "        raise RuntimeError(\"No valid test length across modes.\")\n",
    "\n",
    "    stacked = []\n",
    "    for arr in test_mode_preds:\n",
    "        a = np.asarray(arr)\n",
    "        if len(a) == n_test:\n",
    "            stacked.append(a)\n",
    "        elif len(a) == 0:\n",
    "            stacked.append(np.zeros(n_test))\n",
    "        elif len(a) < n_test:\n",
    "            stacked.append(np.concatenate([a, np.zeros(n_test - len(a))]))\n",
    "        else:\n",
    "            stacked.append(a[:n_test])\n",
    "    stacked = np.array(stacked)  # (K, n_test)\n",
    "\n",
    "    # reconstructed forecast\n",
    "    y_pred_reconstructed = np.sum(stacked, axis=0)\n",
    "    # true test (original df target aligned)\n",
    "    y_true_test = df[target_column].values[lag_steps + val_end : lag_steps + val_end + n_test]\n",
    "\n",
    "    # One-step metrics\n",
    "    one_mae = mean_absolute_error(y_true_test, y_pred_reconstructed)\n",
    "    one_rmse = np.sqrt(mean_squared_error(y_true_test, y_pred_reconstructed))\n",
    "    one_mape = safe_mape(y_true_test, y_pred_reconstructed)\n",
    "    one_sde = sde(y_true_test, y_pred_reconstructed)\n",
    "\n",
    "    one_step_metrics = {\"MAE\": float(one_mae), \"RMSE\": float(one_rmse), \"MAPE (%)\": float(one_mape) if not np.isnan(one_mape) else np.nan, \"SDE\": float(one_sde)}\n",
    "\n",
    "    # Multi-step direct predictions: for each step, retrain each mode's model on TRAIN only with tuned params and predict X_test[:-step]\n",
    "    multistep_rows = []\n",
    "    for step in range(1, max_step_eval + 1):\n",
    "        mode_step_preds = []\n",
    "        valid = True\n",
    "        for info in per_mode_info:\n",
    "            if info.get(\"skipped\", False):\n",
    "                mode_step_preds.append(np.zeros(max(0, n_test - step)))\n",
    "                continue\n",
    "            midx = info[\"mode\"] - 1\n",
    "            # rebuild mode dataset\n",
    "            mode_series = modes[midx, :]\n",
    "            df_mode = df.copy(); df_mode[target_column] = mode_series\n",
    "            X_mode, y_mode = create_multivariate_lagged_dataset(df_mode, target_column, feature_columns, lag=lag_steps)\n",
    "            X_train, y_train = X_mode[:train_end], y_mode[:train_end]\n",
    "            X_test_all, y_test_all = X_mode[val_end:], y_mode[val_end:]\n",
    "            if X_test_all.shape[0] <= step:\n",
    "                valid = False; break\n",
    "            X_test_step = X_test_all[:-step]\n",
    "            # fit on TRAIN only with tuned params\n",
    "            n_hidden = info[\"n_hidden\"]\n",
    "            C = info[\"C\"]\n",
    "            activation = info[\"activation\"]\n",
    "            scaler_train = StandardScaler()\n",
    "            X_train_s = scaler_train.fit_transform(X_train)\n",
    "            X_test_step_s = scaler_train.transform(X_test_step)\n",
    "            model_step = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "            model_step.fit(X_train_s, y_train)\n",
    "            y_pred_step_mode = model_step.predict(X_test_step_s)\n",
    "            mode_step_preds.append(y_pred_step_mode)\n",
    "        if not valid:\n",
    "            break\n",
    "        mode_step_preds = np.array(mode_step_preds)  # (K, n_test-step)\n",
    "        y_pred_step_recon = np.sum(mode_step_preds, axis=0)\n",
    "        y_true_step = df[target_column].values[lag_steps + val_end + step : lag_steps + val_end + step + y_pred_step_recon.shape[0]]\n",
    "        L_true = len(y_true_step); L_pred = len(y_pred_step_recon)\n",
    "        mlen = min(L_true, L_pred)\n",
    "        if mlen == 0:\n",
    "            break\n",
    "        y_true_step = y_true_step[:mlen]; y_pred_step_recon = y_pred_step_recon[:mlen]\n",
    "        multistep_rows.append({\n",
    "            \"Step\": step,\n",
    "            \"MAE\": float(mean_absolute_error(y_true_step, y_pred_step_recon)),\n",
    "            \"RMSE\": float(np.sqrt(mean_squared_error(y_true_step, y_pred_step_recon))),\n",
    "            \"MAPE (%)\": float(safe_mape(y_true_step, y_pred_step_recon)),\n",
    "            \"SDE\": float(sde(y_true_step, y_pred_step_recon))\n",
    "        })\n",
    "\n",
    "    multistep_df = pd.DataFrame(multistep_rows)\n",
    "\n",
    "    return {\n",
    "        \"per_mode_info\": per_mode_info,\n",
    "        \"one_step_metrics\": one_step_metrics,\n",
    "        \"multistep_df\": multistep_df,\n",
    "        \"modes\": modes,\n",
    "        \"omegas\": omegas,\n",
    "        \"y_true_test\": y_true_test,\n",
    "        \"y_pred_reconstructed\": y_pred_reconstructed\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4bdd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['AirTemp','Azimuth','CloudOpacity','DewpointTemp','Dhi','Dni','Ebh',\n",
    "                   'WindDirection10m','Ghi','RelativeHumidity','SurfacePressure','WindSpeed10m']\n",
    "df = pd.read_csv('/Users/hrishityelchuri/Documents/windPred/raw/8.52 hrishit data.csv')\n",
    "\n",
    "df['PeriodEnd'] = pd.to_datetime(df['PeriodEnd'])\n",
    "df['PeriodStart'] = pd.to_datetime(df['PeriodStart'])\n",
    "df = df.sort_values('PeriodEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce278f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-mode best params:\n",
      "   mode  best_val_rmse  n_hidden             C activation  test_len\n",
      "0     1       0.167591       389  10000.000000    sigmoid     20612\n",
      "1     2       0.049934       396      0.215079       relu     20612\n",
      "2     3       0.049497       396      0.000468       relu     20612\n",
      "3     4       0.082513       399      0.000254       relu     20612\n",
      "\n",
      "One-step reconstructed metrics:\n",
      "{'MAE': 0.3713936275258358, 'RMSE': 0.47939256219583354, 'MAPE (%)': 14.015372891320958, 'SDE': 0.47938999193522863}\n",
      "\n",
      "Multi-step reconstructed metrics:\n",
      " Step      MAE     RMSE  MAPE (%)      SDE\n",
      "    1 0.445964 0.582369 16.944894 0.578042\n",
      "    2 0.540181 0.695374 20.165961 0.691748\n",
      "    3 0.650721 0.824224 24.084771 0.821160\n",
      "    4 0.760760 0.953001 27.951795 0.950345\n",
      "    5 0.864433 1.075115 31.607420 1.072754\n",
      "    6 0.960249 1.186708 35.054251 1.184562\n",
      "    7 1.046611 1.286073 38.162725 1.284084\n"
     ]
    }
   ],
   "source": [
    "res = vmd_gwo_relm_pipeline(\n",
    "    df,\n",
    "    target_column='WindSpeed10m',\n",
    "    feature_columns=feature_columns,\n",
    "    lag_steps=12,\n",
    "    K_modes=4,\n",
    "    vmd_alpha=2000.,\n",
    "    vmd_tau=0.,\n",
    "    vmd_init=1,\n",
    "    vmd_DC=0,\n",
    "    vmd_tol=1e-7,\n",
    "    vmd_Niter=500,\n",
    "    gwo_agents=12,\n",
    "    gwo_iters=25,\n",
    "    random_state=42,\n",
    "    Hmin=20, Hmax=400,\n",
    "    Cmin_log=-4, Cmax_log=4,\n",
    "    max_step_eval=7\n",
    ")\n",
    "\n",
    "print(\"Per-mode best params:\")\n",
    "print(pd.DataFrame(res['per_mode_info']))\n",
    "print(\"\\nOne-step reconstructed metrics:\")\n",
    "print(res['one_step_metrics'])\n",
    "print(\"\\nMulti-step reconstructed metrics:\")\n",
    "print(res['multistep_df'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff740b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
