{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d53f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94210260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewt_boundaries_equal_energy(spectrum, N):\n",
    "    energy = np.cumsum(spectrum) / np.sum(spectrum)\n",
    "    boundaries = []\n",
    "    for k in range(1, N):\n",
    "        idx = np.argmin(np.abs(energy - k / N))\n",
    "        boundaries.append(idx / len(spectrum) * np.pi)\n",
    "    return boundaries\n",
    "\n",
    "def ewt_boundaries(spectrum, N, smooth_sigma=2):\n",
    "    spectrum_smooth = gaussian_filter1d(spectrum, sigma=smooth_sigma)\n",
    "    if np.allclose(spectrum_smooth, spectrum_smooth[0]):\n",
    "        return ewt_boundaries_equal_energy(spectrum, N)\n",
    "\n",
    "    peaks, _ = find_peaks(spectrum_smooth)\n",
    "    if len(peaks) < N - 1:\n",
    "        return ewt_boundaries_equal_energy(spectrum, N)\n",
    "\n",
    "    amps = spectrum_smooth[peaks]\n",
    "    top_peaks = sorted([p for _, p in sorted(zip(amps, peaks), reverse=True)][:N-1])\n",
    "    boundaries = [p / len(spectrum) * np.pi for p in top_peaks]\n",
    "    return boundaries\n",
    "\n",
    "def make_filter_bank(boundaries, L):\n",
    "    freqs = np.linspace(0, np.pi, L//2 + 1)\n",
    "    mfb = []\n",
    "    phi = np.zeros_like(freqs)\n",
    "    phi[freqs <= boundaries[0]] = 1\n",
    "    mfb.append(phi)\n",
    "    for i in range(len(boundaries)):\n",
    "        psi = np.zeros_like(freqs)\n",
    "        if i == len(boundaries) - 1:\n",
    "            mask = (freqs > boundaries[i])\n",
    "        else:\n",
    "            mask = (freqs > boundaries[i]) & (freqs <= boundaries[i+1])\n",
    "        psi[mask] = 1\n",
    "        mfb.append(psi)\n",
    "    return mfb\n",
    "\n",
    "def EWT1D(signal, N=3, smooth_sigma=2):\n",
    "    L = len(signal)\n",
    "    spectrum_half = np.abs(fft(signal))[:L//2 + 1]\n",
    "    boundaries = ewt_boundaries(spectrum_half, N, smooth_sigma=smooth_sigma)\n",
    "    mfb = make_filter_bank(boundaries, L)\n",
    "\n",
    "    modes = []\n",
    "    S_full = fft(signal)\n",
    "    for filt in mfb:\n",
    "        filt_full = np.concatenate([filt, filt[-2:0:-1]])\n",
    "        mode_freq = S_full * filt_full\n",
    "        mode_time = np.real(ifft(mode_freq))\n",
    "        modes.append(mode_time)\n",
    "    return np.array(modes), boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2a0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RELM:\n",
    "    def __init__(self, n_hidden=100, activation='tanh', C=1.0, random_state=None):\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.activation = activation\n",
    "        self.C = float(C)\n",
    "        self.random_state = random_state\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _init_weights(self, n_features):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.W = rng.uniform(-1, 1, size=(self.n_hidden, n_features))\n",
    "        self.b = rng.uniform(-1, 1, size=(self.n_hidden,))\n",
    "\n",
    "    def _activation(self, X):\n",
    "        if self.activation == 'sigmoid':\n",
    "            X = np.clip(X, -500, 500)\n",
    "            return 1.0 / (1.0 + np.exp(-X))\n",
    "        if self.activation == 'tanh':\n",
    "            return np.tanh(X)\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0.0, X)\n",
    "        raise ValueError(f\"Unknown activation: {self.activation}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        N, d = X.shape\n",
    "        self._init_weights(d)\n",
    "        H = self._activation(X @ self.W.T + self.b)\n",
    "\n",
    "        if N >= self.n_hidden:\n",
    "            A = (np.eye(self.n_hidden) / self.C) + (H.T @ H)\n",
    "            B = H.T @ y\n",
    "            self.beta = np.linalg.solve(A, B)\n",
    "        else:\n",
    "            A = (np.eye(N) / self.C) + (H @ H.T)\n",
    "            B = y\n",
    "            self.beta = H.T @ np.linalg.solve(A, B)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        H = self._activation(np.asarray(X) @ self.W.T + self.b)\n",
    "        Y = H @ self.beta\n",
    "        return Y.ravel() if Y.shape[1] == 1 else Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad83921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multivariate_lagged_dataset(df, target_col, feature_cols, lag=3):\n",
    "    data = df[feature_cols].values\n",
    "    target_idx = feature_cols.index(target_col)\n",
    "    X, y = [], []\n",
    "    for i in range(lag, len(df)):\n",
    "        X.append(data[i-lag:i].flatten())\n",
    "        y.append(data[i, target_idx])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def safe_mape(y_true, y_pred, min_denom=1.0):\n",
    "    mask = np.abs(y_true) >= min_denom\n",
    "    if np.sum(mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def sde(y_true, y_pred):\n",
    "    return float(np.std(np.array(y_true) - np.array(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46526ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWO:\n",
    "    def __init__(self, obj_func, lb, ub, dim, n_agents=12, n_iter=25, seed=42):\n",
    "        self.obj_func = obj_func\n",
    "        self.lb = np.array(lb)\n",
    "        self.ub = np.array(ub)\n",
    "        self.dim = dim\n",
    "        self.n_agents = n_agents\n",
    "        self.n_iter = n_iter\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def optimize(self):\n",
    "        wolves = self.rng.uniform(self.lb, self.ub, size=(self.n_agents, self.dim))\n",
    "        fitness = np.array([self.obj_func(w) for w in wolves])\n",
    "        idx = np.argsort(fitness)\n",
    "        alpha, beta, delta = wolves[idx[0]], wolves[idx[1]], wolves[idx[2]]\n",
    "        f_alpha, f_beta, f_delta = fitness[idx[0]], fitness[idx[1]], fitness[idx[2]]\n",
    "\n",
    "        for t in range(self.n_iter):\n",
    "            a = 2 - 2 * (t / (self.n_iter - 1 + 1e-9))\n",
    "            for i in range(self.n_agents):\n",
    "                X = wolves[i].copy()\n",
    "                for j in range(self.dim):\n",
    "                    r1, r2 = self.rng.random(), self.rng.random()\n",
    "                    A1 = 2 * a * r1 - a\n",
    "                    C1 = 2 * r2\n",
    "                    D_alpha = abs(C1 * alpha[j] - X[j])\n",
    "                    X1 = alpha[j] - A1 * D_alpha\n",
    "\n",
    "                    r1, r2 = self.rng.random(), self.rng.random()\n",
    "                    A2 = 2 * a * r1 - a\n",
    "                    C2 = 2 * r2\n",
    "                    D_beta = abs(C2 * beta[j] - X[j])\n",
    "                    X2 = beta[j] - A2 * D_beta\n",
    "\n",
    "                    r1, r2 = self.rng.random(), self.rng.random()\n",
    "                    A3 = 2 * a * r1 - a\n",
    "                    C3 = 2 * r2\n",
    "                    D_delta = abs(C3 * delta[j] - X[j])\n",
    "                    X3 = delta[j] - A3 * D_delta\n",
    "\n",
    "                    X[j] = (X1 + X2 + X3) / 3.0\n",
    "\n",
    "                wolves[i] = np.clip(X, self.lb, self.ub)\n",
    "\n",
    "            fitness = np.array([self.obj_func(w) for w in wolves])\n",
    "            idx = np.argsort(fitness)\n",
    "            if fitness[idx[0]] < f_alpha:\n",
    "                alpha, f_alpha = wolves[idx[0]], fitness[idx[0]]\n",
    "            if fitness[idx[1]] < f_beta:\n",
    "                beta, f_beta = wolves[idx[1]], fitness[idx[1]]\n",
    "            if fitness[idx[2]] < f_delta:\n",
    "                delta, f_delta = wolves[idx[2]], fitness[idx[2]]\n",
    "\n",
    "        return alpha, f_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "565a80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_relm_params(position, Hmin=20, Hmax=500, Cmin_log=-4, Cmax_log=4):\n",
    "    h_raw, c_log, a_raw = position\n",
    "    n_hidden = int(np.round(Hmin + h_raw * (Hmax - Hmin)))\n",
    "    C = 10.0 ** float(c_log)\n",
    "    activation = ['tanh', 'sigmoid', 'relu'][int(np.round(np.clip(a_raw, 0, 2)))]\n",
    "    return n_hidden, C, activation\n",
    "\n",
    "def make_relm_objective(X_train, y_train, X_val, y_val, random_state=42):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_val_s = scaler.transform(X_val)\n",
    "\n",
    "    def objective(position):\n",
    "        n_hidden, C, activation = decode_relm_params(position)\n",
    "        try:\n",
    "            model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "            model.fit(X_train_s, y_train)\n",
    "            y_pred = model.predict(X_val_s)\n",
    "            return np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        except:\n",
    "            return 1e6\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c2e7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewt_gwo_relm_no_iewt_multistep(\n",
    "    df,\n",
    "    target_column,\n",
    "    feature_columns,\n",
    "    lag_steps=12,\n",
    "    n_modes=4,\n",
    "    gwo_agents=12,\n",
    "    gwo_iters=25,\n",
    "    random_state=42,\n",
    "    Hmin=20, Hmax=500,\n",
    "    Cmin_log=-4, Cmax_log=4,\n",
    "    smooth_sigma=2,\n",
    "    max_step_eval=7\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - summary_df: DataFrame with per-mode one-step metrics and best hyperparams\n",
    "      - multistep_df: DataFrame rows [Mode, Step, MAE, RMSE, MAPE (%), SDE]\n",
    "    \"\"\"\n",
    "    signal = df[target_column].values\n",
    "    modes, boundaries = EWT1D(signal, N=n_modes, smooth_sigma=smooth_sigma)\n",
    "\n",
    "    n_samples = len(signal) - lag_steps\n",
    "    if n_samples <= 0:\n",
    "        raise ValueError(\"lag_steps too large for series length.\")\n",
    "    train_end = int(0.7 * n_samples)\n",
    "    val_end = int(0.85 * n_samples)\n",
    "\n",
    "    summary_rows = []\n",
    "    multistep_rows = []\n",
    "\n",
    "    for mode_idx in range(n_modes):\n",
    "        mode_series = modes[mode_idx]\n",
    "        df_mode = df.copy()\n",
    "        df_mode[target_column] = mode_series\n",
    "\n",
    "        X_mode, y_mode = create_multivariate_lagged_dataset(df_mode, target_column, feature_columns, lag=lag_steps)\n",
    "        X_train, y_train = X_mode[:train_end], y_mode[:train_end]\n",
    "        X_val, y_val     = X_mode[train_end:val_end], y_mode[train_end:val_end]\n",
    "        X_test, y_test   = X_mode[val_end:], y_mode[val_end:]\n",
    "\n",
    "        if len(X_train) < 5 or len(X_val) < 1 or len(X_test) < 1:\n",
    "            # Not enough data for this split; skip\n",
    "            print(f\"[Mode {mode_idx+1}] Not enough samples for required splits — skipping mode.\")\n",
    "            continue\n",
    "\n",
    "        # GWO objective (tune on train->val)\n",
    "        obj = make_relm_objective(X_train, y_train, X_val, y_val, random_state=random_state)\n",
    "        lb = np.array([0.0, Cmin_log, 0.0], dtype=float)\n",
    "        ub = np.array([1.0, Cmax_log, 2.0], dtype=float)\n",
    "        gwo = GWO(obj, lb, ub, dim=3, n_agents=gwo_agents, n_iter=gwo_iters, seed=random_state + mode_idx)\n",
    "        best_pos, best_fit = gwo.optimize()\n",
    "        n_hidden, C, activation = decode_relm_params(best_pos, Hmin=Hmin, Hmax=Hmax, Cmin_log=Cmin_log, Cmax_log=Cmax_log)\n",
    "\n",
    "        # Train final model on train+val for one-step test evaluation\n",
    "        scaler = StandardScaler()\n",
    "        X_trval = np.vstack([X_train, X_val])\n",
    "        y_trval = np.concatenate([y_train, y_val])\n",
    "        X_trval_s = scaler.fit_transform(X_trval)\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "\n",
    "        model_final = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "        model_final.fit(X_trval_s, y_trval)\n",
    "        y_pred_test = model_final.predict(X_test_s)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        mape = safe_mape(y_test, y_pred_test)\n",
    "        sdev = sde(y_test, y_pred_test)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Mode\": mode_idx + 1,\n",
    "            \"n_hidden\": n_hidden,\n",
    "            \"C\": C,\n",
    "            \"activation\": activation,\n",
    "            \"val_rmse_best\": float(best_fit),\n",
    "            \"MAE\": float(mae),\n",
    "            \"RMSE\": float(rmse),\n",
    "            \"MAPE (%)\": float(mape) if not np.isnan(mape) else np.nan,\n",
    "            \"SDE\": float(sdev)\n",
    "        })\n",
    "\n",
    "        # Multi-step direct forecasts (for steps 1..max_step_eval)\n",
    "        # For fair direct predictions, retrain model on TRAIN only (not train+val)\n",
    "        scaler_train = StandardScaler()\n",
    "        X_train_s = scaler_train.fit_transform(X_train)\n",
    "\n",
    "        for step in range(1, max_step_eval + 1):\n",
    "            # Inputs that can predict t+step are X_test[:-step], targets are y_test[step:]\n",
    "            if X_test.shape[0] <= step:\n",
    "                # Not enough test samples for this step; skip\n",
    "                continue\n",
    "            X_test_step = X_test[:-step]\n",
    "            y_test_step = y_test[step:]\n",
    "\n",
    "            # Fit model on train only with tuned params\n",
    "            model_step = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "            model_step.fit(X_train_s, y_train)\n",
    "\n",
    "            # Scale X_test_step with scaler_train\n",
    "            X_test_step_s = scaler_train.transform(X_test_step)\n",
    "            y_pred_step = model_step.predict(X_test_step_s)\n",
    "\n",
    "            mae_s = mean_absolute_error(y_test_step, y_pred_step)\n",
    "            rmse_s = np.sqrt(mean_squared_error(y_test_step, y_pred_step))\n",
    "            mape_s = safe_mape(y_test_step, y_pred_step)\n",
    "            sdev_s = sde(y_test_step, y_pred_step)\n",
    "\n",
    "            multistep_rows.append({\n",
    "                \"Mode\": mode_idx + 1,\n",
    "                \"Step\": step,\n",
    "                \"MAE\": float(mae_s),\n",
    "                \"RMSE\": float(rmse_s),\n",
    "                \"MAPE (%)\": float(mape_s) if not np.isnan(mape_s) else np.nan,\n",
    "                \"SDE\": float(sdev_s)\n",
    "            })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows).sort_values(\"Mode\").reset_index(drop=True)\n",
    "    multistep_df = pd.DataFrame(multistep_rows).sort_values([\"Mode\", \"Step\"]).reset_index(drop=True)\n",
    "\n",
    "    return summary_df, multistep_df, boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1970ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['AirTemp','Azimuth','CloudOpacity','DewpointTemp','Dhi','Dni','Ebh',\n",
    "                   'WindDirection10m','Ghi','RelativeHumidity','SurfacePressure','WindSpeed10m']\n",
    "df = pd.read_csv('/Users/hrishityelchuri/Documents/windPred/raw/8.52 hrishit data.csv')\n",
    "\n",
    "df['PeriodEnd'] = pd.to_datetime(df['PeriodEnd'])\n",
    "df['PeriodStart'] = pd.to_datetime(df['PeriodStart'])\n",
    "df = df.sort_values('PeriodEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6840c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-mode one-step summary:\n",
      " Mode  n_hidden        C activation  val_rmse_best      MAE     RMSE  MAPE (%)      SDE\n",
      "    1       300 0.023629    sigmoid       0.281201 0.154500 0.201430  6.450085 0.194043\n",
      "    2       108 1.348989    sigmoid       0.048985 0.217639 0.287263 20.694048 0.272769\n",
      "    3       331 0.024686       relu       0.174683 0.182196 0.231931 12.879121 0.231930\n",
      "    4        44 0.028521    sigmoid       0.243659 0.415023 0.539876 65.157607 0.539293\n",
      "\n",
      "Per-mode multi-step (direct) metrics:\n",
      " Mode  Step      MAE     RMSE   MAPE (%)      SDE\n",
      "    1     1 0.300395 0.391473  13.300677 0.288986\n",
      "    1     2 0.300364 0.391472  13.299368 0.289055\n",
      "    1     3 0.300336 0.391471  13.298135 0.289121\n",
      "    1     4 0.300307 0.391471  13.296879 0.289186\n",
      "    1     5 0.300276 0.391470  13.295577 0.289258\n",
      "    1     6 0.300242 0.391469  13.294200 0.289316\n",
      "    1     7 0.300215 0.391469  13.292991 0.289383\n",
      "    2     1 0.267514 0.354597  25.623138 0.321708\n",
      "    2     2 0.267484 0.354588  25.623859 0.321716\n",
      "    2     3 0.267451 0.354576  25.632793 0.321725\n",
      "    2     4 0.267418 0.354565  25.638363 0.321735\n",
      "    2     5 0.267391 0.354559  25.630966 0.321740\n",
      "    2     6 0.267371 0.354556  25.629325 0.321750\n",
      "    2     7 0.267333 0.354540  25.628964 0.321757\n",
      "    3     1 0.261692 0.328966  18.557673 0.327240\n",
      "    3     2 0.326821 0.407853  23.952530 0.406466\n",
      "    3     3 0.395117 0.491717  29.629539 0.490570\n",
      "    3     4 0.462241 0.574812  35.490169 0.573832\n",
      "    3     5 0.525372 0.653703  41.138212 0.652841\n",
      "    3     6 0.583055 0.726241  46.523873 0.725465\n",
      "    3     7 0.634258 0.790881  51.393125 0.790168\n",
      "    4     1 0.499782 0.648662  79.453563 0.648261\n",
      "    4     2 0.553260 0.712607  86.346138 0.712241\n",
      "    4     3 0.597820 0.761530  91.663313 0.761186\n",
      "    4     4 0.634684 0.797659  96.287527 0.797331\n",
      "    4     5 0.666495 0.825591  99.685499 0.825271\n",
      "    4     6 0.694296 0.848368 102.520478 0.848054\n",
      "    4     7 0.714653 0.866157 104.716044 0.865847\n"
     ]
    }
   ],
   "source": [
    "summary_df, multistep_df, boundaries = ewt_gwo_relm_no_iewt_multistep(\n",
    "    df,\n",
    "    target_column='WindSpeed10m',\n",
    "    feature_columns=feature_columns,\n",
    "    lag_steps=12,\n",
    "    n_modes=4,\n",
    "    gwo_agents=12,\n",
    "    gwo_iters=25,\n",
    "    random_state=42,\n",
    "    Hmin=20, Hmax=500,\n",
    "    Cmin_log=-4, Cmax_log=4,\n",
    "    smooth_sigma=2,\n",
    "    max_step_eval=7\n",
    ")\n",
    "print(\"Per-mode one-step summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\nPer-mode multi-step (direct) metrics:\")\n",
    "print(multistep_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fceb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
