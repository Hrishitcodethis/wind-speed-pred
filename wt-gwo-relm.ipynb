{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5342f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.signal import convolve\n",
    "\n",
    "# ============================================\n",
    "# 1. db4 filter coefficients (analysis & synthesis)\n",
    "# ============================================\n",
    "db4_lo = np.array([\n",
    "    -0.010597401785, 0.032883011667, 0.030841381836,\n",
    "    -0.187034811719, -0.027983769417, 0.630880767930,\n",
    "    0.714846570553, 0.230377813309\n",
    "])\n",
    "db4_hi = np.array([\n",
    "    -0.230377813309, 0.714846570553, -0.630880767930,\n",
    "    -0.027983769417, 0.187034811719, 0.030841381836,\n",
    "    -0.032883011667, -0.010597401785\n",
    "])\n",
    "\n",
    "g0 = db4_lo[::-1]\n",
    "g1 = db4_hi[::-1]\n",
    "\n",
    "# ============================================\n",
    "# 2. Convolution with symmetric extension\n",
    "# ============================================\n",
    "def conv_reflect_same(x, filt):\n",
    "    L = len(filt)\n",
    "    ext = L // 2\n",
    "    x_ext = np.pad(x, (ext, ext-1), mode='symmetric')\n",
    "    y = convolve(x_ext, filt, mode='valid')\n",
    "    return y\n",
    "\n",
    "def downsample2(x):\n",
    "    return x[::2]\n",
    "\n",
    "def upsample2(x):\n",
    "    up = np.zeros(len(x) * 2)\n",
    "    up[::2] = x\n",
    "    return up\n",
    "\n",
    "# ============================================\n",
    "# 3. DWT decomposition\n",
    "# ============================================\n",
    "def wt_db4_decompose(x, level=3):\n",
    "    cA = x.copy()\n",
    "    cD_list = []\n",
    "    for _ in range(level):\n",
    "        a = conv_reflect_same(cA, db4_lo)\n",
    "        d = conv_reflect_same(cA, db4_hi)\n",
    "        cA = downsample2(a)\n",
    "        cD = downsample2(d)\n",
    "        cD_list.append(cD)\n",
    "    return cA, cD_list  # cA at final level, list of cD's (level order)\n",
    "\n",
    "# ============================================\n",
    "# 4. Inverse reconstruction (one component at a time)\n",
    "# ============================================\n",
    "def inverse_from_coeffs(cA_L, cD_list, keep='A', keep_index=0):\n",
    "    cA_current = cA_L if keep == 'A' and keep_index == 0 else np.zeros_like(cA_L)\n",
    "    for k in range(len(cD_list)):\n",
    "        cD_current = cD_list[k] if (keep == 'D' and keep_index == k) else np.zeros_like(cD_list[k])\n",
    "        a_up = upsample2(cA_current)\n",
    "        d_up = upsample2(cD_current)\n",
    "        a_rec = conv_reflect_same(a_up, g0)\n",
    "        d_rec = conv_reflect_same(d_up, g1)\n",
    "        # ðŸ”¹ Fix: match lengths\n",
    "        min_len = min(len(a_rec), len(d_rec))\n",
    "        a_rec = a_rec[:min_len]\n",
    "        d_rec = d_rec[:min_len]\n",
    "        cA_current = a_rec + d_rec\n",
    "    return cA_current\n",
    "\n",
    "# ============================================\n",
    "# 5. RELM model\n",
    "# ============================================\n",
    "class RELM:\n",
    "    def __init__(self, n_hidden=100, activation='tanh', C=1.0, random_state=None):\n",
    "        self.n_hidden = int(n_hidden)\n",
    "        self.activation = activation\n",
    "        self.C = float(C)\n",
    "        self.random_state = random_state\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _init_weights(self, n_features):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        self.W = rng.uniform(-1, 1, size=(self.n_hidden, n_features))\n",
    "        self.b = rng.uniform(-1, 1, size=(self.n_hidden,))\n",
    "\n",
    "    def _activation(self, X):\n",
    "        if self.activation == 'sigmoid':\n",
    "            X = np.clip(X, -500, 500)\n",
    "            return 1.0 / (1.0 + np.exp(-X))\n",
    "        if self.activation == 'tanh':\n",
    "            return np.tanh(X)\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0.0, X)\n",
    "        raise ValueError(f\"Unknown activation: {self.activation}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        N, d = X.shape\n",
    "        self._init_weights(d)\n",
    "        H = self._activation(X @ self.W.T + self.b)\n",
    "        if N >= self.n_hidden:\n",
    "            A = (np.eye(self.n_hidden) / self.C) + (H.T @ H)\n",
    "            B = H.T @ y\n",
    "            self.beta = np.linalg.solve(A, B)\n",
    "        else:\n",
    "            A = (np.eye(N) / self.C) + (H @ H.T)\n",
    "            B = y\n",
    "            self.beta = H.T @ np.linalg.solve(A, B)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        H = self._activation(np.asarray(X) @ self.W.T + self.b)\n",
    "        Y = H @ self.beta\n",
    "        return Y.ravel() if Y.shape[1] == 1 else Y\n",
    "\n",
    "# ============================================\n",
    "# 6. GWO optimizer\n",
    "# ============================================\n",
    "class GWO:\n",
    "    def __init__(self, obj_func, lb, ub, dim, n_agents=12, n_iter=25, seed=42):\n",
    "        self.obj_func = obj_func\n",
    "        self.lb = np.array(lb)\n",
    "        self.ub = np.array(ub)\n",
    "        self.dim = dim\n",
    "        self.n_agents = n_agents\n",
    "        self.n_iter = n_iter\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def optimize(self):\n",
    "        wolves = self.rng.uniform(self.lb, self.ub, size=(self.n_agents, self.dim))\n",
    "        fitness = np.array([self.obj_func(w) for w in wolves])\n",
    "        idx = np.argsort(fitness)\n",
    "        alpha, beta, delta = wolves[idx[0]], wolves[idx[1]], wolves[idx[2]]\n",
    "        f_alpha, f_beta, f_delta = fitness[idx[0]], fitness[idx[1]], fitness[idx[2]]\n",
    "\n",
    "        for t in range(self.n_iter):\n",
    "            a = 2 - 2 * (t / (self.n_iter - 1 + 1e-9))\n",
    "            for i in range(self.n_agents):\n",
    "                X = wolves[i].copy()\n",
    "                for j in range(self.dim):\n",
    "                    for leader in [alpha, beta, delta]:\n",
    "                        r1, r2 = self.rng.random(), self.rng.random()\n",
    "                        A = 2 * a * r1 - a\n",
    "                        C = 2 * r2\n",
    "                        D = abs(C * leader[j] - X[j])\n",
    "                        X[j] = leader[j] - A * D\n",
    "                wolves[i] = np.clip(X / 3.0, self.lb, self.ub)\n",
    "            fitness = np.array([self.obj_func(w) for w in wolves])\n",
    "            idx = np.argsort(fitness)\n",
    "            alpha, beta, delta = wolves[idx[0]], wolves[idx[1]], wolves[idx[2]]\n",
    "            f_alpha, f_beta, f_delta = fitness[idx[0]], fitness[idx[1]], fitness[idx[2]]\n",
    "        return alpha, f_alpha\n",
    "\n",
    "# ============================================\n",
    "# 7. Helper functions\n",
    "# ============================================\n",
    "def decode_relm_params(position, Hmin=20, Hmax=500):\n",
    "    h_raw, c_log, a_raw = position\n",
    "    n_hidden = int(np.round(Hmin + h_raw * (Hmax - Hmin)))\n",
    "    C = 10.0 ** float(c_log)\n",
    "    activation = ['tanh', 'sigmoid', 'relu'][int(np.round(np.clip(a_raw, 0, 2)))]\n",
    "    return n_hidden, C, activation\n",
    "\n",
    "def safe_mape(y_true, y_pred, min_denom=1.0):\n",
    "    mask = np.abs(y_true) >= min_denom\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.sum(mask) else np.nan\n",
    "\n",
    "def sde(y_true, y_pred):\n",
    "    return np.std(y_true - y_pred)\n",
    "\n",
    "def create_multivariate_lagged_dataset(df, target_col, feature_cols, lag=3):\n",
    "    data = df[feature_cols].values\n",
    "    target_idx = feature_cols.index(target_col)\n",
    "    X, y = [], []\n",
    "    for i in range(lag, len(df)):\n",
    "        X.append(data[i-lag:i].flatten())\n",
    "        y.append(data[i, target_idx])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_multistep_targets(X, y, max_step=7):\n",
    "    targets = []\n",
    "    for step in range(1, max_step + 1):\n",
    "        targets.append((X[:-step], y[step:]))\n",
    "    return targets\n",
    "\n",
    "# ============================================\n",
    "# 8. Main WTâ€“GWOâ€“RELM pipeline\n",
    "# ============================================\n",
    "def wt_gwo_relm_pipeline_scipy_db4(df, target_column, feature_columns, lag_steps=12, level=3,\n",
    "                                   gwo_agents=12, gwo_iters=25, random_state=42,\n",
    "                                   Hmin=20, Hmax=400, max_step_eval=7):\n",
    "\n",
    "    signal = df[target_column].values\n",
    "    cA_L, cD_list = wt_db4_decompose(signal, level=level)\n",
    "\n",
    "    components = [inverse_from_coeffs(cA_L, cD_list, keep='A', keep_index=0)]\n",
    "    for k in range(len(cD_list)):\n",
    "        components.append(inverse_from_coeffs(cA_L, cD_list, keep='D', keep_index=k))\n",
    "\n",
    "    comp_labels = ['A_L'] + [f'D_{level - i}' for i in range(len(cD_list))]\n",
    "    results_per_comp, multi_results_per_comp = [], {}\n",
    "\n",
    "    for comp_idx, comp_signal in enumerate(components):\n",
    "        # ðŸ”¹ Fix: align lengths before assignment\n",
    "        min_len = min(len(df), len(comp_signal))\n",
    "        df_comp = df.iloc[:min_len].copy()\n",
    "        df_comp[target_column] = comp_signal[:min_len]\n",
    "\n",
    "        X, y = create_multivariate_lagged_dataset(df_comp, target_column, feature_columns, lag=lag_steps)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        train_end = int(0.7 * n_samples)\n",
    "        val_end = int(0.85 * n_samples)\n",
    "\n",
    "        X_train, y_train = X[:train_end], y[:train_end]\n",
    "        X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "        X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_s = scaler.fit_transform(X_train)\n",
    "        X_val_s = scaler.transform(X_val)\n",
    "\n",
    "        def obj_func(position):\n",
    "            n_hidden, C, activation = decode_relm_params(position, Hmin, Hmax)\n",
    "            try:\n",
    "                model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "                model.fit(X_train_s, y_train)\n",
    "                y_pred = model.predict(X_val_s)\n",
    "                return np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            except:\n",
    "                return 1e6\n",
    "\n",
    "        lb = np.array([0.0, -4, 0.0])\n",
    "        ub = np.array([1.0, 4, 2.0])\n",
    "        gwo = GWO(obj_func, lb, ub, dim=3, n_agents=gwo_agents, n_iter=gwo_iters, seed=random_state+comp_idx)\n",
    "        best_pos, _ = gwo.optimize()\n",
    "        n_hidden, C, activation = decode_relm_params(best_pos, Hmin, Hmax)\n",
    "\n",
    "        X_trval = np.vstack([X_train, X_val])\n",
    "        y_trval = np.concatenate([y_train, y_val])\n",
    "        X_trval_s = scaler.fit_transform(X_trval)\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "\n",
    "        model = RELM(n_hidden=n_hidden, activation=activation, C=C, random_state=random_state)\n",
    "        model.fit(X_trval_s, y_trval)\n",
    "        y_pred_test = model.predict(X_test_s)\n",
    "\n",
    "        results_per_comp.append({\n",
    "            \"Component\": comp_labels[comp_idx],\n",
    "            \"n_hidden\": n_hidden, \"C\": C, \"activation\": activation,\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred_test),\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            \"MAPE (%)\": safe_mape(y_test, y_pred_test),\n",
    "            \"SDE\": sde(y_test, y_pred_test)\n",
    "        })\n",
    "\n",
    "        # Multi-step metrics\n",
    "        multi_metrics = []\n",
    "        multistep_data = create_multistep_targets(X_test, y_test, max_step=max_step_eval)\n",
    "        for step, (step_X, step_y) in enumerate(multistep_data, 1):\n",
    "            step_X_s = scaler.transform(step_X)\n",
    "            y_pred_step = model.predict(step_X_s)\n",
    "            multi_metrics.append({\n",
    "                \"Step\": step,\n",
    "                \"MAE\": mean_absolute_error(step_y, y_pred_step),\n",
    "                \"RMSE\": np.sqrt(mean_squared_error(step_y, y_pred_step)),\n",
    "                \"MAPE (%)\": safe_mape(step_y, y_pred_step),\n",
    "                \"SDE\": sde(step_y, y_pred_step)\n",
    "            })\n",
    "        multi_results_per_comp[comp_labels[comp_idx]] = multi_metrics\n",
    "\n",
    "    return {\"per_comp_info\": results_per_comp, \"multistep_per_comp\": multi_results_per_comp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "757a938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = wt_gwo_relm_pipeline_scipy_db4(\n",
    "    df,\n",
    "    target_column=\"WindSpeed10m\",\n",
    "    feature_columns=[\n",
    "        'AirTemp','Azimuth','CloudOpacity','DewpointTemp','Dhi','Dni',\n",
    "        'Ebh','WindDirection10m','Ghi','RelativeHumidity','SurfacePressure','WindSpeed10m'\n",
    "    ],\n",
    "    lag_steps=12,\n",
    "    level=3,\n",
    "    gwo_agents=8,\n",
    "    gwo_iters=10,\n",
    "    random_state=42,\n",
    "    Hmin=20, Hmax=200,\n",
    "    max_step_eval=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d8b9d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-step metrics per component ===\n",
      "  Component  n_hidden         C activation       MAE      RMSE   MAPE (%)  \\\n",
      "0       A_L        20  1.000019       tanh  2.743945  3.234403  64.471782   \n",
      "1       D_3        20  0.999995       tanh  0.012201  0.016758        NaN   \n",
      "2       D_2        20  1.000006       tanh  0.078250  0.103246        NaN   \n",
      "3       D_1        20  1.000000       tanh  0.570033  0.743707  72.518702   \n",
      "\n",
      "        SDE  \n",
      "0  2.097229  \n",
      "1  0.016752  \n",
      "2  0.103034  \n",
      "3  0.743383  \n",
      "\n",
      "=== Multi-step metrics for first component ===\n",
      "Component: A_L\n",
      "   Step       MAE      RMSE   MAPE (%)       SDE\n",
      "0     1  2.743480  3.234232  64.524750  2.096447\n",
      "1     2  2.743462  3.234464  64.273713  2.096146\n",
      "2     3  2.744094  3.236095  64.222175  2.097480\n",
      "3     4  2.745721  3.239437  64.113392  2.101649\n",
      "4     5  2.747975  3.244127  64.204394  2.107869\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== One-step metrics per component ===\")\n",
    "print(pd.DataFrame(res['per_comp_info']))\n",
    "\n",
    "print(\"\\n=== Multi-step metrics for first component ===\")\n",
    "comp_name = list(res['multistep_per_comp'].keys())[0]\n",
    "print(f\"Component: {comp_name}\")\n",
    "print(pd.DataFrame(res['multistep_per_comp'][comp_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fe1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
